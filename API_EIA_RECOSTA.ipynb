{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NntStD374GLu"
      },
      "outputs": [],
      "source": [
        "# Extracción y almacenamiento de datos desde la API de la EIA\n",
        "\n",
        "\"\"\"\n",
        "Este script realiza la extracción de datos sobre consumo y ventas de electricidad en EE.UU.\n",
        "Se implementan dos tipos de extracción:\n",
        "- Full: Descarga todos los datos históricos.\n",
        "- Incremental: Descarga solo los datos del último día.\n",
        "\n",
        "Los datos se almacenan en un Data Lake siguiendo la estructura de capas:\n",
        "- Bronze: Datos crudos obtenidos de la API.\n",
        "- Silver: Datos procesados y limpios.\n",
        "- Gold: Datos listos para análisis.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsR59YDr5aPz",
        "outputId": "9cb79058-cd16-4c28-fee3-41a4258b8c67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Collecting deltalake\n",
            "  Downloading deltalake-0.25.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: pyarrow!=19.0.0,>=16 in /usr/local/lib/python3.11/dist-packages (from deltalake) (18.1.0)\n",
            "Downloading deltalake-0.25.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deltalake\n",
            "Successfully installed deltalake-0.25.5\n"
          ]
        }
      ],
      "source": [
        "#Instalación de bibliotecas para solicitudes HTTP y trabajar con DeltaLake\n",
        "!pip install requests deltalake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z9zCUe3s4hrz"
      },
      "outputs": [],
      "source": [
        "#Importación de librerias y módulos para su uso en las extracciones\n",
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "from configparser import ConfigParser\n",
        "from datetime import datetime, timedelta\n",
        "from deltalake import write_deltalake, DeltaTable\n",
        "import numpy as np\n",
        "from google.colab import files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "fyrqug8MsJ6W",
        "outputId": "ad6849f1-4d81-4953-fb03-b7aa77ce5dcb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-86b31d61-bb45-4747-9ae9-a47fe6c05193\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-86b31d61-bb45-4747-9ae9-a47fe6c05193\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving pipeline.conf to pipeline.conf\n",
            "Token de acceso cargado: [tmdb_api]\n",
            "access_token = WrHnbEfGfLwR67MJKoxvuYvBMJDHLkh8dXqGZmau\n"
          ]
        }
      ],
      "source": [
        "#Para realizar la extracción es necesario el access token, lo he archivado\n",
        "#junto con la entrega de este Colab.\n",
        "#Solo es necesario cargar \"pipeline.conf\" desde el cuadro \"Elegir archivos\"\n",
        "\n",
        "files.upload()  # Esto abrirá el cuadro de diálogo para seleccionar el archivo\n",
        "\n",
        "\n",
        "with open('pipeline.conf', 'r') as file:\n",
        "    access_token = file.read()\n",
        "print(f\"Token de acceso cargado: {access_token}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FB-MltSHUcBr"
      },
      "outputs": [],
      "source": [
        "# Función para obtener credenciales de la API\n",
        "def get_api_config():\n",
        "  parser = ConfigParser()\n",
        "  parser.read(\"pipeline.conf\")\n",
        "  api_credentials = parser[\"tmdb_api\"]\n",
        "  return dict(api_credentials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bPHBr8us56mh"
      },
      "outputs": [],
      "source": [
        "# Definición de los endpoints incremental y full respectivamente\n",
        "ENDPOINTS = {\n",
        "    \"electricity_consumption\": \"https://api.eia.gov/v2/electricity/rto/region-sub-ba-data/data/\",\n",
        "    \"electricity_sales\": \"https://api.eia.gov/v2/electricity/retail-sales/data/\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSJdoIMtHo1i",
        "outputId": "efe32fb0-2ffd-49bf-a5ba-f734552beb26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'access_token': 'WrHnbEfGfLwR67MJKoxvuYvBMJDHLkh8dXqGZmau'}\n"
          ]
        }
      ],
      "source": [
        "# Obtención de token de acceso\n",
        "access_token = get_api_config()\n",
        "api_credentials = get_api_config()\n",
        "print(api_credentials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un72Zhxe4-MT",
        "outputId": "bc5e2cc8-60f4-4d6c-bc76-3bfb48afa4ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       period subba                                  subba-name  value\n",
            "0  2025-04-10  ZONA                                        West   1860\n",
            "15 2025-04-10  KACY       Kansas City Board of Public Utilities    233\n",
            "27 2025-04-10    WR                               Westar Energy   3360\n",
            "26 2025-04-10  WFEC        Western Farmers Electric Cooperative   1071\n",
            "25 2025-04-10  WAUE  Western Area Power Upper Great Plains East   3792\n"
          ]
        }
      ],
      "source": [
        "# Extracción Incremental\n",
        "\n",
        "BASE_URL = ENDPOINTS[\"electricity_consumption\"]\n",
        "access_token = api_credentials[\"access_token\"]\n",
        "\n",
        "fecha_actual = datetime.now()\n",
        "fecha_inicio = (fecha_actual - timedelta(days=1)).strftime('%Y-%m-%d')  # Últimas 24 horas\n",
        "fecha_fin = fecha_actual.strftime('%Y-%m-%d')\n",
        "\n",
        "params = {\n",
        "    \"api_key\": access_token,\n",
        "    \"frequency\": \"hourly\",\n",
        "    \"data[]\": \"value\",\n",
        "    \"start\": fecha_inicio,\n",
        "    \"end\": fecha_fin\n",
        "}\n",
        "\n",
        "response = requests.get(BASE_URL, params=params)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    if \"response\" in data and \"data\" in data[\"response\"]:\n",
        "        df = pd.DataFrame(data[\"response\"][\"data\"])\n",
        "\n",
        "        if 'value' in df.columns:\n",
        "            df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
        "            df['period'] = pd.to_datetime(df['period'])\n",
        "            df = df.sort_values(by='period', ascending=False)\n",
        "\n",
        "        df['fecha'] = df['period'].dt.date\n",
        "        df['hora'] = df['period'].dt.hour\n",
        "\n",
        "        print(df[['period', 'subba', 'subba-name', 'value']].head())\n",
        "\n",
        "        path = \"/content/datalake/bronze/eia/electricity_subba\"\n",
        "\n",
        "        if os.path.exists(path):\n",
        "            existing_df = DeltaTable(path).to_pandas()\n",
        "            df = pd.concat([existing_df, df]).drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "        write_deltalake(path, df, mode=\"append\", partition_by=[\"fecha\", \"hora\"])\n",
        "    else:\n",
        "        print(\"No se encontraron valores.\")\n",
        "else:\n",
        "    print(f\"Error en la solicitud: {response.status_code}, {response.text}\")\n",
        "\n",
        "# - Se extraen datos de consumo eléctrico con frecuencia horaria.\n",
        "# - Debido a la naturaleza dinámica de los datos, se usa una extracción incremental.\n",
        "# - Se almacena en Delta Lake con partición por fecha y hora para facilitar consultas temporales.\n",
        "# - Se usa el modo \"append\" para mantener el histórico de consumo eléctrico.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKdcUmwD-U-7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkYlN95UhSqF",
        "outputId": "573ed7e1-0c35-41c7-b4d0-d138f2b06a93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  period stateid stateDescription sectorid      sectorName customers  \\\n",
            "0   2023      FL          Florida      ALL     all sectors  11541551   \n",
            "1   2023      FL          Florida      COM      commercial   1292988   \n",
            "2   2023      FL          Florida      IND      industrial     26085   \n",
            "3   2022      FL          Florida      ALL     all sectors  11372598   \n",
            "4   2022      FL          Florida      COM      commercial   1282170   \n",
            "5   2022      FL          Florida      IND      industrial     23673   \n",
            "6   2022      FL          Florida      OTH           other      None   \n",
            "7   2022      FL          Florida      RES     residential  10066753   \n",
            "8   2022      FL          Florida      TRA  transportation         2   \n",
            "9   2023      FL          Florida      OTH           other      None   \n",
            "\n",
            "       customers-units  \n",
            "0  number of customers  \n",
            "1  number of customers  \n",
            "2  number of customers  \n",
            "3  number of customers  \n",
            "4  number of customers  \n",
            "5  number of customers  \n",
            "6  number of customers  \n",
            "7  number of customers  \n",
            "8  number of customers  \n",
            "9  number of customers  \n",
            "Valores en 'customers' antes de la limpieza:\n",
            "['11541551' '1292988' '26085' '11372598' '1282170' '23673' None '10066753'\n",
            " '2' '10222476' '9917113' '11213090' '1272939' '23036' '10529937'\n",
            " '1216939' '21289' '9291707' '10830329' '1240902' '23579' '9565846'\n",
            " '10370275' '1199897' '21162' '9149214' '11010395' '1256569' '22587'\n",
            " '9731237' '10673910' '1229559' '21327' '9423022' '11841121' '1312613'\n",
            " '25818' '10502688']\n",
            "Valores en 'customers' después de la limpieza:\n",
            "['11541551' '1292988' '26085' '11372598' '1282170' '23673' '10066753' '2'\n",
            " '10222476' '9917113' '11213090' '1272939' '23036' '10529937' '1216939'\n",
            " '21289' '9291707' '10830329' '1240902' '23579' '9565846' '10370275'\n",
            " '1199897' '21162' '9149214' '11010395' '1256569' '22587' '9731237'\n",
            " '10673910' '1229559' '21327' '9423022' '11841121' '1312613' '25818'\n",
            " '10502688']\n"
          ]
        }
      ],
      "source": [
        "#Extracción Full\n",
        "\n",
        "BASE_URL = ENDPOINTS[\"electricity_sales\"]\n",
        "access_token = api_credentials[\"access_token\"]\n",
        "\n",
        "fecha_actual = datetime.now().year\n",
        "fecha_inicio = \"2014-01-01\"  # Se mantiene el inicio fijo en el año 2000\n",
        "fecha_fin = f\"{fecha_actual}-01-01\"  # Año actual dinámico\n",
        "\n",
        "params = {\n",
        "    \"api_key\": access_token,\n",
        "    \"frequency\": \"annual\",\n",
        "    \"data[]\": \"customers\",\n",
        "    \"facets[stateid][]\": [\"FL\"], # Filtrado por estado de Florida\n",
        "    \"start\": fecha_inicio,\n",
        "    \"end\": fecha_fin\n",
        "}\n",
        "\n",
        "response = requests.get(BASE_URL, params=params)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    if \"response\" in data and \"data\" in data[\"response\"]:\n",
        "        df = pd.DataFrame(data[\"response\"][\"data\"])\n",
        "        print(df.head(10))\n",
        "\n",
        "        # Renombrar columnas\n",
        "        df.rename(columns={'stateid': 'State'}, inplace=True)\n",
        "\n",
        "        # Convertir la columna 'customers' a numérica\n",
        "        df['stateDescription'] = pd.to_numeric(df['stateDescription'], errors='coerce')\n",
        "\n",
        "        # Verificación del tipo de datos y valores en la columna 'customers'\n",
        "        print(\"Valores en 'customers' antes de la limpieza:\")\n",
        "        print(df['customers'].unique())\n",
        "\n",
        "        # Convertir cualquier valor \"None\", 'None', o vacío en NaN\n",
        "        df['customers'] = df['customers'].apply(lambda x: np.nan if str(x).strip().lower() == \"none\" or pd.isnull(x) else x)\n",
        "\n",
        "        # Eliminar filas donde la columna 'customers' sea NaN o tenga valores no válidos\n",
        "        df = df.dropna(subset=['customers'])\n",
        "\n",
        "        # Verificación después de la limpieza\n",
        "        print(\"Valores en 'customers' después de la limpieza:\")\n",
        "        print(df['customers'].unique())\n",
        "\n",
        "        path = \"/content/datalake/bronze/eia/electricity_retail_sales\"\n",
        "\n",
        "        if os.path.exists(path):\n",
        "            existing_df = DeltaTable(path).to_pandas()\n",
        "            df = pd.concat([existing_df, df]).drop_duplicates(subset=None, keep='first', inplace=False).reset_index(drop=True)\n",
        "\n",
        "        write_deltalake(path, df, mode=\"overwrite\", schema_mode=\"merge\")\n",
        "\n",
        "\n",
        "    else:\n",
        "        print(\"No se encontraron datos.\")\n",
        "else:\n",
        "    print(f\"Error en la solicitud: {response.status_code}, {response.text}\")\n",
        "\n",
        "\n",
        "# - Se extraen datos anuales sobre la cantidad de clientes de electricidad en Florida.\n",
        "# - Como los datos cambian solo una vez al año, se utiliza una extracción completa.\n",
        "# - Se almacena en Delta Lake con el modo \"overwrite\" para actualizar los datos sin conservar versiones antiguas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sJBGyWFG4_DP"
      },
      "outputs": [],
      "source": [
        "# Almacenamiento BRONZE\n",
        "def almacenar_datos(data, layer=\"bronze\"):\n",
        "    if not data:\n",
        "        print(\"No hay datos para almacenar.\")\n",
        "        return\n",
        "    df = pd.DataFrame(data[\"response\"][\"data\"])\n",
        "    path = f\"data_lake/{layer}/nuclear_outages/\"\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    df.to_csv(f\"{path}outages_{datetime.today().strftime('%Y-%m-%d')}.csv\", index=False)\n",
        "    print(f\"Datos almacenados en {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3o3mZXDpbcH",
        "outputId": "3ffb1862-f607-46cd-9fcb-0eb1b0220344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos procesados a Silver.\n",
            "Datos procesados a Gold.\n"
          ]
        }
      ],
      "source": [
        "# Almacenamiento SILVER\n",
        "def process_bronze_to_silver():\n",
        "    bronze_path = \"/content/datalake/bronze/eia/electricity_subba\"\n",
        "    silver_path = \"/content/datalake/silver/eia/electricity_subba\"\n",
        "\n",
        "    if not os.path.exists(bronze_path):\n",
        "        print(\"No hay datos en Bronze.\")\n",
        "        return\n",
        "\n",
        "    df = DeltaTable(bronze_path).to_pandas()\n",
        "\n",
        "    # Transformaciones: limpieza y normalización\n",
        "    df = df.dropna()\n",
        "    df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
        "    df['period'] = pd.to_datetime(df['period'])\n",
        "    df = df.sort_values(by='period', ascending=False)\n",
        "    df = df.drop_duplicates()\n",
        "\n",
        "    # Reseteo el índice para evitar duplicado\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    write_deltalake(silver_path, df, mode=\"overwrite\", partition_by=[\"fecha\"])\n",
        "    print(\"Datos procesados a Silver.\")\n",
        "\n",
        "#Almacenamiento GOLD\n",
        "def process_silver_to_gold():\n",
        "    silver_path = \"/content/datalake/silver/eia/electricity_subba\"\n",
        "    gold_path = \"/content/datalake/gold/eia/electricity_aggregates\"\n",
        "\n",
        "    if not os.path.exists(silver_path):\n",
        "        print(\"No hay datos en Silver.\")\n",
        "        return\n",
        "\n",
        "    df = DeltaTable(silver_path).to_pandas()\n",
        "\n",
        "    # Promedio de valores por día\n",
        "    df_gold = df.groupby(\"fecha\")[\"value\"].mean().reset_index()\n",
        "    df_gold.rename(columns={\"value\": \"avg_value\"}, inplace=True)\n",
        "\n",
        "    # Reseteo índice para evitar duplicado\n",
        "    df_gold.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    write_deltalake(gold_path, df_gold, mode=\"overwrite\")\n",
        "    print(\"Datos procesados a Gold.\")\n",
        "\n",
        "# Ejecutar los procesos\n",
        "process_bronze_to_silver()\n",
        "process_silver_to_gold()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}